%\input{0_praeambel.tex}
%\input{0_declare.tex}
\thispagestyle{empty}
%\begin{document}
\vspace*{1cm}
\section*{Abstract}

Deep Learning is becoming a standard tool across science and industry to optimally solve a variety of tasks.
A challenge of great importance for the research program carried over at the Large Hadron Collider is realising a generative model to sample synthetic data from a desired probability density.
While generative models such as Generative Adversarial Networks and Normalizing Flows have been originally designed to solve Machine Learning tasks such as classification and data generation, we illustrate how they can also be employed to statistically invert Monte Carlo simulations of detector effects. 
In particular, we show how conditional Generative Adversarial Networks and Normalizing Flows are capable of unfolding detector effects, using ZW production at the LHC as a benchmarking process.

Two technical by-products of interest stemming from these studies are the introduction of a Bayesian Normalizing Flow and of the Latent Space Refinement (LaSeR) protocol. The former has been introduced in order to address the crucial question of explainability and uncertainty estimation of deep generative models, which is achieved by reformulating the training and prediction phases of Normalizing Flows as a Bayesian inference task. Finally, LaSeR is a method to refine a model's output using classifier weights. We show how LaSeR can critically improve the performances of a Normalizing Flow whenever the training data contains topological obstructions.

\vspace*{2.2cm}
\section*{Zusammenfassung}

Deep Learning wird gegenwärtig in Wissenschaft und Industrie zu einem Standardwerkzeug, um unterschiedlichste Aufgaben optimal zu lösen.
Eine Herausforderung von großer Bedeutung für LHC-Analysen ist die Realisierung eines generativen Modells, um synthetische Daten aus einer gewünschten Wahrscheinlichkeitsdichte zu generieren. Während generative Modelle wie Generative Adversarial Networks und Normalizing Flows ursprünglich entwickelt wurden, um Machine-Learning-Aufgaben wie Klassifikation und Datengenerierung zu lösen, zeigen wir, wie sie auch verwendet werden können, um Monte-Carlo-Simulationen von Detektoreffekten statistisch zu invertieren.
Insbesondere zeigen wir, wie conditional-Generative Adversarial Networks und -Normalizing Flows Detektoreffekte umkehren können, indem wir die ZW-Produktion am LHC als Benchmarking-Prozess verwenden.

Zwei interessante technische Nebenprodukte aus diesen Studien sind die Einführung einer Bayesian-Normalizing Flow und des Latent Space Refinement (LaSeR)-Protokolls. Ersteres wurde eingeführt, um die entscheidende Frage der Erklärbarkeit und Unsicherheitsschätzung von tiefen generativen Modellen zu beantworten, die durch die Neuformulierung der Trainings- und Vorhersagephasen von Normalizing Flows als Bayes'sche Inferenzaufgabe erreicht wird. Letzeteres ist eine Methode, um die Ausgabe eines Modells mithilfe von Klassifikatorgewichten zu verfeinern. Wir zeigen, wie LaSeR die Leistung einer Normalizing Flow entscheidend verbessern kann, wenn die Trainingsdaten topologische Hindernisse enthalten.

%\end{document}
